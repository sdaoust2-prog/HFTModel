{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Predictor - Enhanced with Full Evaluation\n",
    "\n",
    "Random Forest model with comprehensive evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, confusion_matrix, classification_report,\n",
    "    precision_recall_fscore_support, roc_curve, roc_auc_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"vFDjkUVRfPnedLrbRjm75BZ9CJHz3dfv\"\n",
    "TICKER = \"AAPL\"\n",
    "START_DATE = \"2025-10-01\"\n",
    "END_DATE = \"2025-11-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_polygon_data(ticker, start, end, api_key):\n",
    "    url = f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/minute/{start}/{end}?apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    if 'results' not in data or len(data['results']) < 2:\n",
    "        raise ValueError(\"Not enough data returned from Polygon API\")\n",
    "    \n",
    "    df = pd.DataFrame(data['results'])\n",
    "    df['timestamp'] = pd.to_datetime(df['t'], unit='ms')\n",
    "    df = df.rename(columns={'o':'open','h':'high','l':'low','c':'close','v':'volume'})\n",
    "    df = df[['timestamp','open','high','low','close','volume']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Momentum & volatility\n",
    "    df['momentum_1min'] = df['close'].pct_change()\n",
    "    df['volatility_1min'] = df['momentum_1min'] ** 2\n",
    "    \n",
    "    # Price direction\n",
    "    df['price_direction'] = (df['close'] > df['open']).astype(int)\n",
    "    \n",
    "    # VWAP and deviation\n",
    "    df['vwap'] = (df['close'] * df['volume']).cumsum() / df['volume'].cumsum()\n",
    "    df['vwap_dev'] = (df['close'] - df['vwap']) / df['vwap']\n",
    "    \n",
    "    # Time features\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['minute'] = df['timestamp'].dt.minute\n",
    "    \n",
    "    # Target: next-minute movement\n",
    "    df['next_return'] = df['close'].shift(-1) / df['close'] - 1\n",
    "    df['target'] = (df['next_return'] > 0).astype(int)\n",
    "    \n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pull_polygon_data(TICKER, START_DATE, END_DATE, API_KEY)\n",
    "df = calculate_features(df)\n",
    "\n",
    "features = ['momentum_1min', 'volatility_1min', 'price_direction', 'vwap_dev', 'hour', 'minute']\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# Chronological train/test split\n",
    "split_index = int(len(X)*0.8)\n",
    "X_train, X_test = X.iloc[:split_index], X.iloc[split_index:]\n",
    "y_train, y_test = y.iloc[:split_index], y.iloc[split_index:]\n",
    "\n",
    "print(f\"train size: {len(X_train)}\")\n",
    "print(f\"test size: {len(X_test)}\")\n",
    "print(f\"train UP ratio: {y_train.mean():.3f}\")\n",
    "print(f\"test UP ratio: {y_test.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "# Probabilities (for ROC curve)\n",
    "y_prob_train = model.predict_proba(X_train)[:, 1]\n",
    "y_prob_test = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_train = confusion_matrix(y_train, y_pred_train)\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "sns.heatmap(cm_train, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['DOWN', 'UP'], yticklabels=['DOWN', 'UP'])\n",
    "axes[0].set_title('Training Set Confusion Matrix')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "\n",
    "sns.heatmap(cm_test, annot=True, fmt='d', cmap='Blues', ax=axes[1],\n",
    "            xticklabels=['DOWN', 'UP'], yticklabels=['DOWN', 'UP'])\n",
    "axes[1].set_title('Test Set Confusion Matrix')\n",
    "axes[1].set_ylabel('Actual')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# calculate TP, TN, FP, FN\n",
    "tn, fp, fn, tp = cm_test.ravel()\n",
    "print(f\"\\nTest Set Breakdown:\")\n",
    "print(f\"True Negatives (correct DOWN predictions): {tn}\")\n",
    "print(f\"False Positives (predicted UP, was DOWN): {fp}\")\n",
    "print(f\"False Negatives (predicted DOWN, was UP): {fn}\")\n",
    "print(f\"True Positives (correct UP predictions): {tp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, Recall, F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== TRAINING SET ===\")\n",
    "print(classification_report(y_train, y_pred_train, target_names=['DOWN', 'UP']))\n",
    "\n",
    "print(\"\\n=== TEST SET ===\")\n",
    "print(classification_report(y_test, y_pred_test, target_names=['DOWN', 'UP']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC Curve and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate ROC curves\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, y_prob_train)\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_prob_test)\n",
    "\n",
    "auc_train = roc_auc_score(y_train, y_prob_train)\n",
    "auc_test = roc_auc_score(y_test, y_prob_test)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_train, tpr_train, label=f'Train (AUC={auc_train:.4f})', linewidth=2)\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test (AUC={auc_test:.4f})', linewidth=2)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random (AUC=0.5)', alpha=0.5)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTrain AUC: {auc_train:.4f}\")\n",
    "print(f\"Test AUC: {auc_test:.4f}\")\n",
    "print(f\"Overfitting gap: {auc_train - auc_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = model.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': importances\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['feature'], importance_df['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train vs Test Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate metrics\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "train_prec, train_rec, train_f1, _ = precision_recall_fscore_support(y_train, y_pred_train, average='weighted')\n",
    "test_prec, test_rec, test_f1, _ = precision_recall_fscore_support(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {'metric': 'Accuracy', 'train': train_acc, 'test': test_acc, 'gap': train_acc - test_acc},\n",
    "    {'metric': 'Precision', 'train': train_prec, 'test': test_prec, 'gap': train_prec - test_prec},\n",
    "    {'metric': 'Recall', 'train': train_rec, 'test': test_rec, 'gap': train_rec - test_rec},\n",
    "    {'metric': 'F1-Score', 'train': train_f1, 'test': test_f1, 'gap': train_f1 - test_f1},\n",
    "    {'metric': 'AUC', 'train': auc_train, 'test': auc_test, 'gap': auc_train - auc_test}\n",
    "])\n",
    "\n",
    "print(\"\\n=== TRAIN VS TEST COMPARISON ===\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "# visual comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(len(comparison))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, comparison['train'], width, label='Train', alpha=0.8)\n",
    "ax.bar(x + width/2, comparison['test'], width, label='Test', alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Performance: Train vs Test')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison['metric'])\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, \"trained_stock_model.pkl\")\n",
    "print(\"Model saved to trained_stock_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recent_minute_decision(ticker, api_key, model, prob_threshold=0.55):\n",
    "    today = datetime.now().date()\n",
    "    start = today - timedelta(days=1)\n",
    "    \n",
    "    # Pull data\n",
    "    df = pull_polygon_data(ticker, start, today, api_key)\n",
    "    \n",
    "    # Only last 2 minutes needed for momentum, volatility, price direction\n",
    "    last_two = df.iloc[-2:]\n",
    "    \n",
    "    momentum_1min = (last_two['close'].iloc[1] - last_two['close'].iloc[0]) / last_two['close'].iloc[0]\n",
    "    volatility_1min = momentum_1min ** 2\n",
    "    price_direction = int(last_two['close'].iloc[1] > last_two['open'].iloc[1])\n",
    "    \n",
    "    # VWAP deviation using cumulative VWAP\n",
    "    vwap = (df['close'] * df['volume']).cumsum() / df['volume'].cumsum()\n",
    "    vwap_dev = (last_two['close'].iloc[1] - vwap.iloc[-1]) / vwap.iloc[-1]\n",
    "    \n",
    "    hour = last_two['timestamp'].iloc[1].hour\n",
    "    minute = last_two['timestamp'].iloc[1].minute\n",
    "    \n",
    "    feature_row = pd.DataFrame([{\n",
    "        'momentum_1min': momentum_1min,\n",
    "        'volatility_1min': volatility_1min,\n",
    "        'price_direction': price_direction,\n",
    "        'vwap_dev': vwap_dev,\n",
    "        'hour': hour,\n",
    "        'minute': minute\n",
    "    }])\n",
    "    \n",
    "    # Model prediction\n",
    "    pred_proba = model.predict_proba(feature_row)[0]\n",
    "    \n",
    "    # Decision logic with HOLD for uncertain predictions\n",
    "    if pred_proba[1] > prob_threshold:\n",
    "        decision = \"BUY\"\n",
    "    elif pred_proba[0] > prob_threshold:\n",
    "        decision = \"SELL\"\n",
    "    else:\n",
    "        decision = \"HOLD\"\n",
    "    \n",
    "    return decision, last_two.iloc[1], feature_row, pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"trained_stock_model.pkl\")\n",
    "\n",
    "decision, last_bar, features_used, pred_proba = get_recent_minute_decision(TICKER, API_KEY, model)\n",
    "print(\"Decision:\", decision)\n",
    "print(\"Last bar:\\n\", last_bar)\n",
    "print(\"Features:\\n\", features_used)\n",
    "print(\"Predicted probabilities (DOWN, UP):\", pred_proba)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
