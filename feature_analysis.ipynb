{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Return Analysis\n",
    "\n",
    "Analyze which features are predictive of future returns using:\n",
    "- Information Coefficient (IC): correlation between feature and forward returns\n",
    "- Spearman rank correlation (robust to outliers)\n",
    "- Feature vs return scatter plots\n",
    "- Correlation heatmaps\n",
    "- IC curves over different horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "API_KEY = \"vFDjkUVRfPnedLrbRjm75BZ9CJHz3dfv\"\n",
    "TICKER = \"AAPL\"\n",
    "START_DATE = \"2025-10-01\"\n",
    "END_DATE = \"2025-11-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_polygon_data(ticker, start, end, api_key):\n",
    "    url = f\"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/minute/{start}/{end}?apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    if 'results' not in data or len(data['results']) < 2:\n",
    "        raise ValueError(\"not enough data\")\n",
    "    \n",
    "    df = pd.DataFrame(data['results'])\n",
    "    df['timestamp'] = pd.to_datetime(df['t'], unit='ms')\n",
    "    df = df.rename(columns={'o':'open','h':'high','l':'low','c':'close','v':'volume'})\n",
    "    df = df[['timestamp','open','high','low','close','volume']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_features_with_horizons(df, forward_horizons=[1, 2, 3, 5]):\n",
    "    \"\"\"Calculate features and forward returns at multiple horizons\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # features\n",
    "    df['momentum_1min'] = df['close'].pct_change()\n",
    "    df['volatility_1min'] = df['momentum_1min'] ** 2\n",
    "    df['price_direction'] = (df['close'] > df['open']).astype(int)\n",
    "    df['vwap'] = (df['close'] * df['volume']).cumsum() / df['volume'].cumsum()\n",
    "    df['vwap_dev'] = (df['close'] - df['vwap']) / df['vwap']\n",
    "    df['hour'] = df['timestamp'].dt.hour\n",
    "    df['minute'] = df['timestamp'].dt.minute\n",
    "    \n",
    "    # forward returns at different horizons\n",
    "    for h in forward_horizons:\n",
    "        df[f'return_{h}min'] = df['close'].shift(-h) / df['close'] - 1\n",
    "    \n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and prepare data\n",
    "print(f\"loading data for {TICKER}...\")\n",
    "df = pull_polygon_data(TICKER, START_DATE, END_DATE, API_KEY)\n",
    "df = calculate_features_with_horizons(df, forward_horizons=[1, 2, 3, 5])\n",
    "print(f\"loaded {len(df)} bars\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Coefficient Analysis\n",
    "\n",
    "IC measures correlation between feature values and forward returns.\n",
    "- Pearson IC: linear correlation\n",
    "- Spearman IC: rank correlation (robust to outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ic(df, features, return_col='return_1min'):\n",
    "    \"\"\"Calculate Information Coefficient for each feature\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for feat in features:\n",
    "        # pearson correlation\n",
    "        pearson_ic, p_pearson = pearsonr(df[feat], df[return_col])\n",
    "        \n",
    "        # spearman rank correlation (robust to outliers)\n",
    "        spearman_ic, p_spearman = spearmanr(df[feat], df[return_col])\n",
    "        \n",
    "        results.append({\n",
    "            'feature': feat,\n",
    "            'pearson_ic': pearson_ic,\n",
    "            'pearson_pvalue': p_pearson,\n",
    "            'spearman_ic': spearman_ic,\n",
    "            'spearman_pvalue': p_spearman\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results).sort_values('pearson_ic', key=abs, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['momentum_1min', 'volatility_1min', 'price_direction', 'vwap_dev', 'hour', 'minute']\n",
    "\n",
    "ic_results = calculate_ic(df, features, return_col='return_1min')\n",
    "print(\"\\nInformation Coefficient Rankings (1-min forward return):\")\n",
    "print(ic_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IC Curves Over Different Horizons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate IC for each feature at different horizons\n",
    "horizons = [1, 2, 3, 5]\n",
    "ic_by_horizon = {}\n",
    "\n",
    "for h in horizons:\n",
    "    ic_by_horizon[h] = calculate_ic(df, features, return_col=f'return_{h}min')\n",
    "\n",
    "# plot IC curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "for feat in features:\n",
    "    pearson_ics = [ic_by_horizon[h].loc[ic_by_horizon[h]['feature'] == feat, 'pearson_ic'].values[0] for h in horizons]\n",
    "    spearman_ics = [ic_by_horizon[h].loc[ic_by_horizon[h]['feature'] == feat, 'spearman_ic'].values[0] for h in horizons]\n",
    "    \n",
    "    axes[0].plot(horizons, pearson_ics, marker='o', label=feat)\n",
    "    axes[1].plot(horizons, spearman_ics, marker='o', label=feat)\n",
    "\n",
    "axes[0].set_xlabel('Forward Horizon (minutes)')\n",
    "axes[0].set_ylabel('Pearson IC')\n",
    "axes[0].set_title('Pearson IC vs Horizon')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "axes[0].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "\n",
    "axes[1].set_xlabel('Forward Horizon (minutes)')\n",
    "axes[1].set_ylabel('Spearman IC')\n",
    "axes[1].set_title('Spearman IC vs Horizon')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "axes[1].axhline(y=0, color='black', linestyle='--', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature vs Return Scatter Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(features):\n",
    "    axes[i].scatter(df[feat], df['return_1min'], alpha=0.3, s=10)\n",
    "    axes[i].set_xlabel(feat)\n",
    "    axes[i].set_ylabel('1-min forward return')\n",
    "    axes[i].set_title(f'{feat} vs return')\n",
    "    axes[i].axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "    axes[i].axvline(x=0, color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # add IC annotation\n",
    "    ic_val = ic_results.loc[ic_results['feature'] == feat, 'pearson_ic'].values[0]\n",
    "    axes[i].text(0.05, 0.95, f'IC={ic_val:.4f}', transform=axes[i].transAxes, \n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix\n",
    "corr_matrix = df[features + ['return_1min']].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.3f', cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Winsorization Analysis\n",
    "\n",
    "Check if extreme outliers are skewing the IC. Winsorize features (cap at percentiles) and recalculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winsorize(series, lower=0.01, upper=0.99):\n",
    "    \"\"\"Cap values at lower and upper percentiles\"\"\"\n",
    "    lower_val = series.quantile(lower)\n",
    "    upper_val = series.quantile(upper)\n",
    "    return series.clip(lower=lower_val, upper=upper_val)\n",
    "\n",
    "# create winsorized features\n",
    "df_wins = df.copy()\n",
    "for feat in features:\n",
    "    df_wins[f'{feat}_wins'] = winsorize(df[feat])\n",
    "\n",
    "# compare IC before and after winsorization\n",
    "ic_original = calculate_ic(df, features, 'return_1min')\n",
    "ic_winsorized = calculate_ic(df_wins, [f'{f}_wins' for f in features], 'return_1min')\n",
    "ic_winsorized['feature'] = ic_winsorized['feature'].str.replace('_wins', '')\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'original_ic': ic_original['pearson_ic'].values,\n",
    "    'winsorized_ic': ic_winsorized['pearson_ic'].values,\n",
    "    'ic_change': ic_winsorized['pearson_ic'].values - ic_original['pearson_ic'].values\n",
    "})\n",
    "\n",
    "print(\"\\nImpact of Winsorization on IC:\")\n",
    "print(comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, feat in enumerate(features):\n",
    "    axes[i].hist(df[feat], bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[i].set_xlabel(feat)\n",
    "    axes[i].set_ylabel('frequency')\n",
    "    axes[i].set_title(f'{feat} distribution')\n",
    "    axes[i].axvline(x=df[feat].mean(), color='red', linestyle='--', label='mean')\n",
    "    axes[i].axvline(x=df[feat].median(), color='green', linestyle='--', label='median')\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFeature Summary Statistics:\")\n",
    "print(df[features].describe())\n",
    "\n",
    "print(\"\\nForward Return Summary Statistics:\")\n",
    "print(df[['return_1min', 'return_2min', 'return_3min', 'return_5min']].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
